// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: batches.sql

package db

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const cancelBatch = `-- name: CancelBatch :one
UPDATE batches
SET status = CASE
        WHEN status = 'validating' THEN 'cancelled'
        ELSE 'cancelling'
    END,
    cancelled_at = CASE WHEN status = 'validating' THEN NOW() ELSE cancelled_at END,
    cancelling_at = CASE WHEN status <> 'validating' THEN NOW() ELSE cancelling_at END,
    updated_at = NOW()
WHERE tenant_id = $1 AND id = $2 AND status IN ('validating', 'in_progress', 'finalizing')
RETURNING id, tenant_id, api_key_id, status, endpoint, input_file_id, result_file_id, error_file_id, errors, completion_window, max_concurrency, metadata, request_count_total, request_count_completed, request_count_failed, request_count_cancelled, created_at, updated_at, in_progress_at, completed_at, cancelled_at, cancelling_at, finalizing_at, failed_at, expires_at, expired_at
`

type CancelBatchParams struct {
	TenantID pgtype.UUID `json:"tenant_id"`
	ID       pgtype.UUID `json:"id"`
}

func (q *Queries) CancelBatch(ctx context.Context, arg CancelBatchParams) (Batch, error) {
	row := q.db.QueryRow(ctx, cancelBatch, arg.TenantID, arg.ID)
	var i Batch
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.ApiKeyID,
		&i.Status,
		&i.Endpoint,
		&i.InputFileID,
		&i.ResultFileID,
		&i.ErrorFileID,
		&i.Errors,
		&i.CompletionWindow,
		&i.MaxConcurrency,
		&i.Metadata,
		&i.RequestCountTotal,
		&i.RequestCountCompleted,
		&i.RequestCountFailed,
		&i.RequestCountCancelled,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.InProgressAt,
		&i.CompletedAt,
		&i.CancelledAt,
		&i.CancellingAt,
		&i.FinalizingAt,
		&i.FailedAt,
		&i.ExpiresAt,
		&i.ExpiredAt,
	)
	return i, err
}

const claimNextBatchItem = `-- name: ClaimNextBatchItem :one
WITH next_item AS (
    SELECT bi.id
    FROM batch_items bi
    JOIN batches b ON b.id = bi.batch_id
    WHERE bi.batch_id = $1
      AND bi.status = 'queued'
      AND b.status = 'in_progress'
    ORDER BY bi.item_index
    LIMIT 1
    FOR UPDATE SKIP LOCKED
)
UPDATE batch_items
SET status = 'running',
    started_at = NOW()
WHERE id = (SELECT id FROM next_item)
RETURNING id, batch_id, item_index, status, custom_id, input, response, error, created_at, started_at, completed_at
`

func (q *Queries) ClaimNextBatchItem(ctx context.Context, batchID pgtype.UUID) (BatchItem, error) {
	row := q.db.QueryRow(ctx, claimNextBatchItem, batchID)
	var i BatchItem
	err := row.Scan(
		&i.ID,
		&i.BatchID,
		&i.ItemIndex,
		&i.Status,
		&i.CustomID,
		&i.Input,
		&i.Response,
		&i.Error,
		&i.CreatedAt,
		&i.StartedAt,
		&i.CompletedAt,
	)
	return i, err
}

const completeBatchItem = `-- name: CompleteBatchItem :exec
UPDATE batch_items
SET status = 'completed',
    completed_at = NOW(),
    response = $2
WHERE id = $1
`

type CompleteBatchItemParams struct {
	ID       pgtype.UUID `json:"id"`
	Response []byte      `json:"response"`
}

func (q *Queries) CompleteBatchItem(ctx context.Context, arg CompleteBatchItemParams) error {
	_, err := q.db.Exec(ctx, completeBatchItem, arg.ID, arg.Response)
	return err
}

const createBatch = `-- name: CreateBatch :one
INSERT INTO batches (
    tenant_id,
    api_key_id,
    status,
    endpoint,
    input_file_id,
    completion_window,
    max_concurrency,
    metadata,
    request_count_total,
    expires_at
) VALUES (
    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10
) RETURNING id, tenant_id, api_key_id, status, endpoint, input_file_id, result_file_id, error_file_id, errors, completion_window, max_concurrency, metadata, request_count_total, request_count_completed, request_count_failed, request_count_cancelled, created_at, updated_at, in_progress_at, completed_at, cancelled_at, cancelling_at, finalizing_at, failed_at, expires_at, expired_at
`

type CreateBatchParams struct {
	TenantID          pgtype.UUID        `json:"tenant_id"`
	ApiKeyID          pgtype.UUID        `json:"api_key_id"`
	Status            string             `json:"status"`
	Endpoint          string             `json:"endpoint"`
	InputFileID       pgtype.UUID        `json:"input_file_id"`
	CompletionWindow  pgtype.Text        `json:"completion_window"`
	MaxConcurrency    int32              `json:"max_concurrency"`
	Metadata          []byte             `json:"metadata"`
	RequestCountTotal int32              `json:"request_count_total"`
	ExpiresAt         pgtype.Timestamptz `json:"expires_at"`
}

func (q *Queries) CreateBatch(ctx context.Context, arg CreateBatchParams) (Batch, error) {
	row := q.db.QueryRow(ctx, createBatch,
		arg.TenantID,
		arg.ApiKeyID,
		arg.Status,
		arg.Endpoint,
		arg.InputFileID,
		arg.CompletionWindow,
		arg.MaxConcurrency,
		arg.Metadata,
		arg.RequestCountTotal,
		arg.ExpiresAt,
	)
	var i Batch
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.ApiKeyID,
		&i.Status,
		&i.Endpoint,
		&i.InputFileID,
		&i.ResultFileID,
		&i.ErrorFileID,
		&i.Errors,
		&i.CompletionWindow,
		&i.MaxConcurrency,
		&i.Metadata,
		&i.RequestCountTotal,
		&i.RequestCountCompleted,
		&i.RequestCountFailed,
		&i.RequestCountCancelled,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.InProgressAt,
		&i.CompletedAt,
		&i.CancelledAt,
		&i.CancellingAt,
		&i.FinalizingAt,
		&i.FailedAt,
		&i.ExpiresAt,
		&i.ExpiredAt,
	)
	return i, err
}

const failBatchItem = `-- name: FailBatchItem :exec
UPDATE batch_items
SET status = 'failed',
    completed_at = NOW(),
    error = $2
WHERE id = $1
`

type FailBatchItemParams struct {
	ID    pgtype.UUID `json:"id"`
	Error []byte      `json:"error"`
}

func (q *Queries) FailBatchItem(ctx context.Context, arg FailBatchItemParams) error {
	_, err := q.db.Exec(ctx, failBatchItem, arg.ID, arg.Error)
	return err
}

const getBatch = `-- name: GetBatch :one
SELECT id, tenant_id, api_key_id, status, endpoint, input_file_id, result_file_id, error_file_id, errors, completion_window, max_concurrency, metadata, request_count_total, request_count_completed, request_count_failed, request_count_cancelled, created_at, updated_at, in_progress_at, completed_at, cancelled_at, cancelling_at, finalizing_at, failed_at, expires_at, expired_at
FROM batches
WHERE tenant_id = $1 AND id = $2
`

type GetBatchParams struct {
	TenantID pgtype.UUID `json:"tenant_id"`
	ID       pgtype.UUID `json:"id"`
}

func (q *Queries) GetBatch(ctx context.Context, arg GetBatchParams) (Batch, error) {
	row := q.db.QueryRow(ctx, getBatch, arg.TenantID, arg.ID)
	var i Batch
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.ApiKeyID,
		&i.Status,
		&i.Endpoint,
		&i.InputFileID,
		&i.ResultFileID,
		&i.ErrorFileID,
		&i.Errors,
		&i.CompletionWindow,
		&i.MaxConcurrency,
		&i.Metadata,
		&i.RequestCountTotal,
		&i.RequestCountCompleted,
		&i.RequestCountFailed,
		&i.RequestCountCancelled,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.InProgressAt,
		&i.CompletedAt,
		&i.CancelledAt,
		&i.CancellingAt,
		&i.FinalizingAt,
		&i.FailedAt,
		&i.ExpiresAt,
		&i.ExpiredAt,
	)
	return i, err
}

const getBatchByID = `-- name: GetBatchByID :one
SELECT id, tenant_id, api_key_id, status, endpoint, input_file_id, result_file_id, error_file_id, errors, completion_window, max_concurrency, metadata, request_count_total, request_count_completed, request_count_failed, request_count_cancelled, created_at, updated_at, in_progress_at, completed_at, cancelled_at, cancelling_at, finalizing_at, failed_at, expires_at, expired_at
FROM batches
WHERE id = $1
`

func (q *Queries) GetBatchByID(ctx context.Context, id pgtype.UUID) (Batch, error) {
	row := q.db.QueryRow(ctx, getBatchByID, id)
	var i Batch
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.ApiKeyID,
		&i.Status,
		&i.Endpoint,
		&i.InputFileID,
		&i.ResultFileID,
		&i.ErrorFileID,
		&i.Errors,
		&i.CompletionWindow,
		&i.MaxConcurrency,
		&i.Metadata,
		&i.RequestCountTotal,
		&i.RequestCountCompleted,
		&i.RequestCountFailed,
		&i.RequestCountCancelled,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.InProgressAt,
		&i.CompletedAt,
		&i.CancelledAt,
		&i.CancellingAt,
		&i.FinalizingAt,
		&i.FailedAt,
		&i.ExpiresAt,
		&i.ExpiredAt,
	)
	return i, err
}

const getOldestQueuedBatch = `-- name: GetOldestQueuedBatch :one
SELECT id, tenant_id, api_key_id, status, endpoint, input_file_id, result_file_id, error_file_id, errors, completion_window, max_concurrency, metadata, request_count_total, request_count_completed, request_count_failed, request_count_cancelled, created_at, updated_at, in_progress_at, completed_at, cancelled_at, cancelling_at, finalizing_at, failed_at, expires_at, expired_at
FROM batches
WHERE status = 'validating'
ORDER BY created_at
LIMIT 1
FOR UPDATE SKIP LOCKED
`

func (q *Queries) GetOldestQueuedBatch(ctx context.Context) (Batch, error) {
	row := q.db.QueryRow(ctx, getOldestQueuedBatch)
	var i Batch
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.ApiKeyID,
		&i.Status,
		&i.Endpoint,
		&i.InputFileID,
		&i.ResultFileID,
		&i.ErrorFileID,
		&i.Errors,
		&i.CompletionWindow,
		&i.MaxConcurrency,
		&i.Metadata,
		&i.RequestCountTotal,
		&i.RequestCountCompleted,
		&i.RequestCountFailed,
		&i.RequestCountCancelled,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.InProgressAt,
		&i.CompletedAt,
		&i.CancelledAt,
		&i.CancellingAt,
		&i.FinalizingAt,
		&i.FailedAt,
		&i.ExpiresAt,
		&i.ExpiredAt,
	)
	return i, err
}

const incrementBatchCounts = `-- name: IncrementBatchCounts :exec
UPDATE batches
SET request_count_completed = request_count_completed + $2,
    request_count_failed = request_count_failed + $3,
    request_count_cancelled = request_count_cancelled + $4,
    updated_at = NOW()
WHERE id = $1
`

type IncrementBatchCountsParams struct {
	ID                    pgtype.UUID `json:"id"`
	RequestCountCompleted int32       `json:"request_count_completed"`
	RequestCountFailed    int32       `json:"request_count_failed"`
	RequestCountCancelled int32       `json:"request_count_cancelled"`
}

func (q *Queries) IncrementBatchCounts(ctx context.Context, arg IncrementBatchCountsParams) error {
	_, err := q.db.Exec(ctx, incrementBatchCounts,
		arg.ID,
		arg.RequestCountCompleted,
		arg.RequestCountFailed,
		arg.RequestCountCancelled,
	)
	return err
}

const insertBatchItem = `-- name: InsertBatchItem :one
INSERT INTO batch_items (
    batch_id,
    item_index,
    status,
    custom_id,
    input
) VALUES ($1, $2, $3, $4, $5)
RETURNING id, batch_id, item_index, status, custom_id, input, response, error, created_at, started_at, completed_at
`

type InsertBatchItemParams struct {
	BatchID   pgtype.UUID `json:"batch_id"`
	ItemIndex int64       `json:"item_index"`
	Status    string      `json:"status"`
	CustomID  pgtype.Text `json:"custom_id"`
	Input     []byte      `json:"input"`
}

func (q *Queries) InsertBatchItem(ctx context.Context, arg InsertBatchItemParams) (BatchItem, error) {
	row := q.db.QueryRow(ctx, insertBatchItem,
		arg.BatchID,
		arg.ItemIndex,
		arg.Status,
		arg.CustomID,
		arg.Input,
	)
	var i BatchItem
	err := row.Scan(
		&i.ID,
		&i.BatchID,
		&i.ItemIndex,
		&i.Status,
		&i.CustomID,
		&i.Input,
		&i.Response,
		&i.Error,
		&i.CreatedAt,
		&i.StartedAt,
		&i.CompletedAt,
	)
	return i, err
}

const listBatchItemsForOutput = `-- name: ListBatchItemsForOutput :many
SELECT id, batch_id, item_index, status, custom_id, input, response, error, created_at, started_at, completed_at
FROM batch_items
WHERE batch_id = $1
ORDER BY item_index
`

func (q *Queries) ListBatchItemsForOutput(ctx context.Context, batchID pgtype.UUID) ([]BatchItem, error) {
	rows, err := q.db.Query(ctx, listBatchItemsForOutput, batchID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []BatchItem{}
	for rows.Next() {
		var i BatchItem
		if err := rows.Scan(
			&i.ID,
			&i.BatchID,
			&i.ItemIndex,
			&i.Status,
			&i.CustomID,
			&i.Input,
			&i.Response,
			&i.Error,
			&i.CreatedAt,
			&i.StartedAt,
			&i.CompletedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listBatches = `-- name: ListBatches :many
SELECT id, tenant_id, api_key_id, status, endpoint, input_file_id, result_file_id, error_file_id, errors, completion_window, max_concurrency, metadata, request_count_total, request_count_completed, request_count_failed, request_count_cancelled, created_at, updated_at, in_progress_at, completed_at, cancelled_at, cancelling_at, finalizing_at, failed_at, expires_at, expired_at
FROM batches
WHERE tenant_id = $1
ORDER BY created_at DESC
LIMIT $2 OFFSET $3
`

type ListBatchesParams struct {
	TenantID pgtype.UUID `json:"tenant_id"`
	Limit    int32       `json:"limit"`
	Offset   int32       `json:"offset"`
}

func (q *Queries) ListBatches(ctx context.Context, arg ListBatchesParams) ([]Batch, error) {
	rows, err := q.db.Query(ctx, listBatches, arg.TenantID, arg.Limit, arg.Offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Batch{}
	for rows.Next() {
		var i Batch
		if err := rows.Scan(
			&i.ID,
			&i.TenantID,
			&i.ApiKeyID,
			&i.Status,
			&i.Endpoint,
			&i.InputFileID,
			&i.ResultFileID,
			&i.ErrorFileID,
			&i.Errors,
			&i.CompletionWindow,
			&i.MaxConcurrency,
			&i.Metadata,
			&i.RequestCountTotal,
			&i.RequestCountCompleted,
			&i.RequestCountFailed,
			&i.RequestCountCancelled,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.InProgressAt,
			&i.CompletedAt,
			&i.CancelledAt,
			&i.CancellingAt,
			&i.FinalizingAt,
			&i.FailedAt,
			&i.ExpiresAt,
			&i.ExpiredAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listBatchesAdmin = `-- name: ListBatchesAdmin :many
SELECT b.id, b.tenant_id, b.api_key_id, b.status, b.endpoint, b.input_file_id, b.result_file_id, b.error_file_id, b.errors, b.completion_window, b.max_concurrency, b.metadata, b.request_count_total, b.request_count_completed, b.request_count_failed, b.request_count_cancelled, b.created_at, b.updated_at, b.in_progress_at, b.completed_at, b.cancelled_at, b.cancelling_at, b.finalizing_at, b.failed_at, b.expires_at, b.expired_at, t.name AS tenant_name, COUNT(*) OVER() AS total_count
FROM batches b
JOIN tenants t ON t.id = b.tenant_id
WHERE ($1::uuid IS NULL OR b.tenant_id = $1)
  AND (
    $2::text[] IS NULL
    OR cardinality($2) = 0
    OR b.status = ANY($2)
  )
  AND (
    $3::text IS NULL
    OR b.endpoint ILIKE '%' || $3 || '%'
    OR t.name ILIKE '%' || $3 || '%'
    OR b.id::text ILIKE '%' || $3 || '%'
    OR b.metadata::text ILIKE '%' || $3 || '%'
  )
ORDER BY b.created_at DESC
LIMIT $5 OFFSET $4
`

type ListBatchesAdminParams struct {
	TenantID   pgtype.UUID `json:"tenant_id"`
	Statuses   []string    `json:"statuses"`
	Search     pgtype.Text `json:"search"`
	PageOffset int32       `json:"page_offset"`
	PageLimit  int32       `json:"page_limit"`
}

type ListBatchesAdminRow struct {
	ID                    pgtype.UUID        `json:"id"`
	TenantID              pgtype.UUID        `json:"tenant_id"`
	ApiKeyID              pgtype.UUID        `json:"api_key_id"`
	Status                string             `json:"status"`
	Endpoint              string             `json:"endpoint"`
	InputFileID           pgtype.UUID        `json:"input_file_id"`
	ResultFileID          pgtype.UUID        `json:"result_file_id"`
	ErrorFileID           pgtype.UUID        `json:"error_file_id"`
	Errors                []byte             `json:"errors"`
	CompletionWindow      pgtype.Text        `json:"completion_window"`
	MaxConcurrency        int32              `json:"max_concurrency"`
	Metadata              []byte             `json:"metadata"`
	RequestCountTotal     int32              `json:"request_count_total"`
	RequestCountCompleted int32              `json:"request_count_completed"`
	RequestCountFailed    int32              `json:"request_count_failed"`
	RequestCountCancelled int32              `json:"request_count_cancelled"`
	CreatedAt             pgtype.Timestamptz `json:"created_at"`
	UpdatedAt             pgtype.Timestamptz `json:"updated_at"`
	InProgressAt          pgtype.Timestamptz `json:"in_progress_at"`
	CompletedAt           pgtype.Timestamptz `json:"completed_at"`
	CancelledAt           pgtype.Timestamptz `json:"cancelled_at"`
	CancellingAt          pgtype.Timestamptz `json:"cancelling_at"`
	FinalizingAt          pgtype.Timestamptz `json:"finalizing_at"`
	FailedAt              pgtype.Timestamptz `json:"failed_at"`
	ExpiresAt             pgtype.Timestamptz `json:"expires_at"`
	ExpiredAt             pgtype.Timestamptz `json:"expired_at"`
	TenantName            string             `json:"tenant_name"`
	TotalCount            int64              `json:"total_count"`
}

func (q *Queries) ListBatchesAdmin(ctx context.Context, arg ListBatchesAdminParams) ([]ListBatchesAdminRow, error) {
	rows, err := q.db.Query(ctx, listBatchesAdmin,
		arg.TenantID,
		arg.Statuses,
		arg.Search,
		arg.PageOffset,
		arg.PageLimit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []ListBatchesAdminRow{}
	for rows.Next() {
		var i ListBatchesAdminRow
		if err := rows.Scan(
			&i.ID,
			&i.TenantID,
			&i.ApiKeyID,
			&i.Status,
			&i.Endpoint,
			&i.InputFileID,
			&i.ResultFileID,
			&i.ErrorFileID,
			&i.Errors,
			&i.CompletionWindow,
			&i.MaxConcurrency,
			&i.Metadata,
			&i.RequestCountTotal,
			&i.RequestCountCompleted,
			&i.RequestCountFailed,
			&i.RequestCountCancelled,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.InProgressAt,
			&i.CompletedAt,
			&i.CancelledAt,
			&i.CancellingAt,
			&i.FinalizingAt,
			&i.FailedAt,
			&i.ExpiresAt,
			&i.ExpiredAt,
			&i.TenantName,
			&i.TotalCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listBatchesCursor = `-- name: ListBatchesCursor :many
WITH anchor AS (
    SELECT b.created_at, b.id
    FROM batches b
    WHERE b.id = $3::uuid
)
SELECT b.id, b.tenant_id, b.api_key_id, b.status, b.endpoint, b.input_file_id, b.result_file_id, b.error_file_id, b.errors, b.completion_window, b.max_concurrency, b.metadata, b.request_count_total, b.request_count_completed, b.request_count_failed, b.request_count_cancelled, b.created_at, b.updated_at, b.in_progress_at, b.completed_at, b.cancelled_at, b.cancelling_at, b.finalizing_at, b.failed_at, b.expires_at, b.expired_at
FROM batches b
LEFT JOIN anchor a ON true
WHERE b.tenant_id = $1
  AND (
        a.created_at IS NULL
        OR b.created_at < a.created_at
        OR (b.created_at = a.created_at AND b.id < a.id)
  )
ORDER BY b.created_at DESC, b.id DESC
LIMIT $2
`

type ListBatchesCursorParams struct {
	TenantID pgtype.UUID `json:"tenant_id"`
	Limit    int32       `json:"limit"`
	AfterID  pgtype.UUID `json:"after_id"`
}

func (q *Queries) ListBatchesCursor(ctx context.Context, arg ListBatchesCursorParams) ([]Batch, error) {
	rows, err := q.db.Query(ctx, listBatchesCursor, arg.TenantID, arg.Limit, arg.AfterID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Batch{}
	for rows.Next() {
		var i Batch
		if err := rows.Scan(
			&i.ID,
			&i.TenantID,
			&i.ApiKeyID,
			&i.Status,
			&i.Endpoint,
			&i.InputFileID,
			&i.ResultFileID,
			&i.ErrorFileID,
			&i.Errors,
			&i.CompletionWindow,
			&i.MaxConcurrency,
			&i.Metadata,
			&i.RequestCountTotal,
			&i.RequestCountCompleted,
			&i.RequestCountFailed,
			&i.RequestCountCancelled,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.InProgressAt,
			&i.CompletedAt,
			&i.CancelledAt,
			&i.CancellingAt,
			&i.FinalizingAt,
			&i.FailedAt,
			&i.ExpiresAt,
			&i.ExpiredAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const markBatchFinalStatus = `-- name: MarkBatchFinalStatus :one
UPDATE batches
SET status = $2,
    completed_at = CASE WHEN $2 = 'completed' THEN NOW() ELSE completed_at END,
    failed_at = CASE WHEN $2 = 'failed' THEN NOW() ELSE failed_at END,
    finalizing_at = CASE WHEN $2 = 'finalizing' THEN NOW() ELSE finalizing_at END,
    cancelled_at = CASE WHEN $2 = 'cancelled' THEN NOW() ELSE cancelled_at END,
    cancelling_at = CASE WHEN $2 = 'cancelling' THEN NOW() ELSE cancelling_at END,
    expired_at = CASE WHEN $2 = 'expired' THEN NOW() ELSE expired_at END,
    result_file_id = $3,
    error_file_id = $4,
    errors = COALESCE($5::jsonb, errors),
    updated_at = NOW()
WHERE id = $1
RETURNING id, tenant_id, api_key_id, status, endpoint, input_file_id, result_file_id, error_file_id, errors, completion_window, max_concurrency, metadata, request_count_total, request_count_completed, request_count_failed, request_count_cancelled, created_at, updated_at, in_progress_at, completed_at, cancelled_at, cancelling_at, finalizing_at, failed_at, expires_at, expired_at
`

type MarkBatchFinalStatusParams struct {
	ID           pgtype.UUID `json:"id"`
	Status       string      `json:"status"`
	ResultFileID pgtype.UUID `json:"result_file_id"`
	ErrorFileID  pgtype.UUID `json:"error_file_id"`
	Errors       []byte      `json:"errors"`
}

func (q *Queries) MarkBatchFinalStatus(ctx context.Context, arg MarkBatchFinalStatusParams) (Batch, error) {
	row := q.db.QueryRow(ctx, markBatchFinalStatus,
		arg.ID,
		arg.Status,
		arg.ResultFileID,
		arg.ErrorFileID,
		arg.Errors,
	)
	var i Batch
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.ApiKeyID,
		&i.Status,
		&i.Endpoint,
		&i.InputFileID,
		&i.ResultFileID,
		&i.ErrorFileID,
		&i.Errors,
		&i.CompletionWindow,
		&i.MaxConcurrency,
		&i.Metadata,
		&i.RequestCountTotal,
		&i.RequestCountCompleted,
		&i.RequestCountFailed,
		&i.RequestCountCancelled,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.InProgressAt,
		&i.CompletedAt,
		&i.CancelledAt,
		&i.CancellingAt,
		&i.FinalizingAt,
		&i.FailedAt,
		&i.ExpiresAt,
		&i.ExpiredAt,
	)
	return i, err
}

const markBatchInProgress = `-- name: MarkBatchInProgress :one
UPDATE batches
SET status = 'in_progress',
    in_progress_at = NOW(),
    updated_at = NOW()
WHERE id = $1 AND status = 'validating'
RETURNING id, tenant_id, api_key_id, status, endpoint, input_file_id, result_file_id, error_file_id, errors, completion_window, max_concurrency, metadata, request_count_total, request_count_completed, request_count_failed, request_count_cancelled, created_at, updated_at, in_progress_at, completed_at, cancelled_at, cancelling_at, finalizing_at, failed_at, expires_at, expired_at
`

func (q *Queries) MarkBatchInProgress(ctx context.Context, id pgtype.UUID) (Batch, error) {
	row := q.db.QueryRow(ctx, markBatchInProgress, id)
	var i Batch
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.ApiKeyID,
		&i.Status,
		&i.Endpoint,
		&i.InputFileID,
		&i.ResultFileID,
		&i.ErrorFileID,
		&i.Errors,
		&i.CompletionWindow,
		&i.MaxConcurrency,
		&i.Metadata,
		&i.RequestCountTotal,
		&i.RequestCountCompleted,
		&i.RequestCountFailed,
		&i.RequestCountCancelled,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.InProgressAt,
		&i.CompletedAt,
		&i.CancelledAt,
		&i.CancellingAt,
		&i.FinalizingAt,
		&i.FailedAt,
		&i.ExpiresAt,
		&i.ExpiredAt,
	)
	return i, err
}

const updateBatchCounts = `-- name: UpdateBatchCounts :one
UPDATE batches
SET request_count_total = request_count_total + $2,
    updated_at = NOW()
WHERE id = $1
RETURNING id, tenant_id, api_key_id, status, endpoint, input_file_id, result_file_id, error_file_id, errors, completion_window, max_concurrency, metadata, request_count_total, request_count_completed, request_count_failed, request_count_cancelled, created_at, updated_at, in_progress_at, completed_at, cancelled_at, cancelling_at, finalizing_at, failed_at, expires_at, expired_at
`

type UpdateBatchCountsParams struct {
	ID                pgtype.UUID `json:"id"`
	RequestCountTotal int32       `json:"request_count_total"`
}

func (q *Queries) UpdateBatchCounts(ctx context.Context, arg UpdateBatchCountsParams) (Batch, error) {
	row := q.db.QueryRow(ctx, updateBatchCounts, arg.ID, arg.RequestCountTotal)
	var i Batch
	err := row.Scan(
		&i.ID,
		&i.TenantID,
		&i.ApiKeyID,
		&i.Status,
		&i.Endpoint,
		&i.InputFileID,
		&i.ResultFileID,
		&i.ErrorFileID,
		&i.Errors,
		&i.CompletionWindow,
		&i.MaxConcurrency,
		&i.Metadata,
		&i.RequestCountTotal,
		&i.RequestCountCompleted,
		&i.RequestCountFailed,
		&i.RequestCountCancelled,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.InProgressAt,
		&i.CompletedAt,
		&i.CancelledAt,
		&i.CancellingAt,
		&i.FinalizingAt,
		&i.FailedAt,
		&i.ExpiresAt,
		&i.ExpiredAt,
	)
	return i, err
}
